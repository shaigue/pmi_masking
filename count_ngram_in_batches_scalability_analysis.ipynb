{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f067029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7439e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment parameters\n",
    "ngram_count_batch_size = 1_000_000\n",
    "n_samples = 30_000_000\n",
    "n_workers = 3\n",
    "max_ngram_size = 5\n",
    "filter_ngram_count_threshold = 2\n",
    "save_dir = Path('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193b30b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/1/count_table_0-999999.parquet'),\n",
       " WindowsPath('data/1/count_table_1000000-1999999.parquet'),\n",
       " WindowsPath('data/1/count_table_10000000-10999999.parquet'),\n",
       " WindowsPath('data/1/count_table_11000000-11999999.parquet'),\n",
       " WindowsPath('data/1/count_table_12000000-12999999.parquet'),\n",
       " WindowsPath('data/1/count_table_13000000-13999999.parquet'),\n",
       " WindowsPath('data/1/count_table_14000000-14999999.parquet'),\n",
       " WindowsPath('data/1/count_table_15000000-15999999.parquet'),\n",
       " WindowsPath('data/1/count_table_16000000-16999999.parquet'),\n",
       " WindowsPath('data/1/count_table_17000000-17999999.parquet'),\n",
       " WindowsPath('data/1/count_table_18000000-18999999.parquet'),\n",
       " WindowsPath('data/1/count_table_19000000-19999999.parquet'),\n",
       " WindowsPath('data/1/count_table_2000000-2999999.parquet'),\n",
       " WindowsPath('data/1/count_table_20000000-20999999.parquet'),\n",
       " WindowsPath('data/1/count_table_21000000-21999999.parquet'),\n",
       " WindowsPath('data/1/count_table_22000000-22999999.parquet'),\n",
       " WindowsPath('data/1/count_table_23000000-23999999.parquet'),\n",
       " WindowsPath('data/1/count_table_24000000-24999999.parquet'),\n",
       " WindowsPath('data/1/count_table_25000000-25999999.parquet'),\n",
       " WindowsPath('data/1/count_table_26000000-26999999.parquet'),\n",
       " WindowsPath('data/1/count_table_27000000-27999999.parquet'),\n",
       " WindowsPath('data/1/count_table_28000000-28999999.parquet'),\n",
       " WindowsPath('data/1/count_table_29000000-29999999.parquet'),\n",
       " WindowsPath('data/1/count_table_3000000-3999999.parquet'),\n",
       " WindowsPath('data/1/count_table_4000000-4999999.parquet'),\n",
       " WindowsPath('data/1/count_table_5000000-5999999.parquet'),\n",
       " WindowsPath('data/1/count_table_6000000-6999999.parquet'),\n",
       " WindowsPath('data/1/count_table_7000000-7999999.parquet'),\n",
       " WindowsPath('data/1/count_table_8000000-8999999.parquet'),\n",
       " WindowsPath('data/1/count_table_9000000-9999999.parquet'),\n",
       " WindowsPath('data/2/count_table_0-999999.parquet'),\n",
       " WindowsPath('data/2/count_table_1000000-1999999.parquet'),\n",
       " WindowsPath('data/2/count_table_10000000-10999999.parquet'),\n",
       " WindowsPath('data/2/count_table_11000000-11999999.parquet'),\n",
       " WindowsPath('data/2/count_table_12000000-12999999.parquet'),\n",
       " WindowsPath('data/2/count_table_13000000-13999999.parquet'),\n",
       " WindowsPath('data/2/count_table_14000000-14999999.parquet'),\n",
       " WindowsPath('data/2/count_table_15000000-15999999.parquet'),\n",
       " WindowsPath('data/2/count_table_16000000-16999999.parquet'),\n",
       " WindowsPath('data/2/count_table_17000000-17999999.parquet'),\n",
       " WindowsPath('data/2/count_table_18000000-18999999.parquet'),\n",
       " WindowsPath('data/2/count_table_19000000-19999999.parquet'),\n",
       " WindowsPath('data/2/count_table_2000000-2999999.parquet'),\n",
       " WindowsPath('data/2/count_table_20000000-20999999.parquet'),\n",
       " WindowsPath('data/2/count_table_21000000-21999999.parquet'),\n",
       " WindowsPath('data/2/count_table_22000000-22999999.parquet'),\n",
       " WindowsPath('data/2/count_table_23000000-23999999.parquet'),\n",
       " WindowsPath('data/2/count_table_24000000-24999999.parquet'),\n",
       " WindowsPath('data/2/count_table_25000000-25999999.parquet'),\n",
       " WindowsPath('data/2/count_table_26000000-26999999.parquet'),\n",
       " WindowsPath('data/2/count_table_27000000-27999999.parquet'),\n",
       " WindowsPath('data/2/count_table_28000000-28999999.parquet'),\n",
       " WindowsPath('data/2/count_table_29000000-29999999.parquet'),\n",
       " WindowsPath('data/2/count_table_3000000-3999999.parquet'),\n",
       " WindowsPath('data/2/count_table_4000000-4999999.parquet'),\n",
       " WindowsPath('data/2/count_table_5000000-5999999.parquet'),\n",
       " WindowsPath('data/2/count_table_6000000-6999999.parquet'),\n",
       " WindowsPath('data/2/count_table_7000000-7999999.parquet'),\n",
       " WindowsPath('data/2/count_table_8000000-8999999.parquet'),\n",
       " WindowsPath('data/2/count_table_9000000-9999999.parquet'),\n",
       " WindowsPath('data/3/count_table_0-999999.parquet'),\n",
       " WindowsPath('data/3/count_table_1000000-1999999.parquet'),\n",
       " WindowsPath('data/3/count_table_10000000-10999999.parquet'),\n",
       " WindowsPath('data/3/count_table_11000000-11999999.parquet'),\n",
       " WindowsPath('data/3/count_table_12000000-12999999.parquet'),\n",
       " WindowsPath('data/3/count_table_13000000-13999999.parquet'),\n",
       " WindowsPath('data/3/count_table_14000000-14999999.parquet'),\n",
       " WindowsPath('data/3/count_table_15000000-15999999.parquet'),\n",
       " WindowsPath('data/3/count_table_16000000-16999999.parquet'),\n",
       " WindowsPath('data/3/count_table_17000000-17999999.parquet'),\n",
       " WindowsPath('data/3/count_table_18000000-18999999.parquet'),\n",
       " WindowsPath('data/3/count_table_19000000-19999999.parquet'),\n",
       " WindowsPath('data/3/count_table_2000000-2999999.parquet'),\n",
       " WindowsPath('data/3/count_table_20000000-20999999.parquet'),\n",
       " WindowsPath('data/3/count_table_21000000-21999999.parquet'),\n",
       " WindowsPath('data/3/count_table_22000000-22999999.parquet'),\n",
       " WindowsPath('data/3/count_table_23000000-23999999.parquet'),\n",
       " WindowsPath('data/3/count_table_24000000-24999999.parquet'),\n",
       " WindowsPath('data/3/count_table_25000000-25999999.parquet'),\n",
       " WindowsPath('data/3/count_table_26000000-26999999.parquet'),\n",
       " WindowsPath('data/3/count_table_27000000-27999999.parquet'),\n",
       " WindowsPath('data/3/count_table_28000000-28999999.parquet'),\n",
       " WindowsPath('data/3/count_table_29000000-29999999.parquet'),\n",
       " WindowsPath('data/3/count_table_3000000-3999999.parquet'),\n",
       " WindowsPath('data/3/count_table_4000000-4999999.parquet'),\n",
       " WindowsPath('data/3/count_table_5000000-5999999.parquet'),\n",
       " WindowsPath('data/3/count_table_6000000-6999999.parquet'),\n",
       " WindowsPath('data/3/count_table_7000000-7999999.parquet'),\n",
       " WindowsPath('data/3/count_table_8000000-8999999.parquet'),\n",
       " WindowsPath('data/3/count_table_9000000-9999999.parquet'),\n",
       " WindowsPath('data/4/count_table_0-999999.parquet'),\n",
       " WindowsPath('data/4/count_table_1000000-1999999.parquet'),\n",
       " WindowsPath('data/4/count_table_10000000-10999999.parquet'),\n",
       " WindowsPath('data/4/count_table_11000000-11999999.parquet'),\n",
       " WindowsPath('data/4/count_table_12000000-12999999.parquet'),\n",
       " WindowsPath('data/4/count_table_13000000-13999999.parquet'),\n",
       " WindowsPath('data/4/count_table_14000000-14999999.parquet'),\n",
       " WindowsPath('data/4/count_table_15000000-15999999.parquet'),\n",
       " WindowsPath('data/4/count_table_16000000-16999999.parquet'),\n",
       " WindowsPath('data/4/count_table_17000000-17999999.parquet'),\n",
       " WindowsPath('data/4/count_table_18000000-18999999.parquet'),\n",
       " WindowsPath('data/4/count_table_19000000-19999999.parquet'),\n",
       " WindowsPath('data/4/count_table_2000000-2999999.parquet'),\n",
       " WindowsPath('data/4/count_table_20000000-20999999.parquet'),\n",
       " WindowsPath('data/4/count_table_21000000-21999999.parquet'),\n",
       " WindowsPath('data/4/count_table_22000000-22999999.parquet'),\n",
       " WindowsPath('data/4/count_table_23000000-23999999.parquet'),\n",
       " WindowsPath('data/4/count_table_24000000-24999999.parquet'),\n",
       " WindowsPath('data/4/count_table_25000000-25999999.parquet'),\n",
       " WindowsPath('data/4/count_table_26000000-26999999.parquet'),\n",
       " WindowsPath('data/4/count_table_27000000-27999999.parquet'),\n",
       " WindowsPath('data/4/count_table_28000000-28999999.parquet'),\n",
       " WindowsPath('data/4/count_table_29000000-29999999.parquet'),\n",
       " WindowsPath('data/4/count_table_3000000-3999999.parquet'),\n",
       " WindowsPath('data/4/count_table_4000000-4999999.parquet'),\n",
       " WindowsPath('data/4/count_table_5000000-5999999.parquet'),\n",
       " WindowsPath('data/4/count_table_6000000-6999999.parquet'),\n",
       " WindowsPath('data/4/count_table_7000000-7999999.parquet'),\n",
       " WindowsPath('data/4/count_table_8000000-8999999.parquet'),\n",
       " WindowsPath('data/4/count_table_9000000-9999999.parquet'),\n",
       " WindowsPath('data/5/count_table_0-999999.parquet'),\n",
       " WindowsPath('data/5/count_table_1000000-1999999.parquet'),\n",
       " WindowsPath('data/5/count_table_10000000-10999999.parquet'),\n",
       " WindowsPath('data/5/count_table_11000000-11999999.parquet'),\n",
       " WindowsPath('data/5/count_table_12000000-12999999.parquet'),\n",
       " WindowsPath('data/5/count_table_13000000-13999999.parquet'),\n",
       " WindowsPath('data/5/count_table_14000000-14999999.parquet'),\n",
       " WindowsPath('data/5/count_table_15000000-15999999.parquet'),\n",
       " WindowsPath('data/5/count_table_16000000-16999999.parquet'),\n",
       " WindowsPath('data/5/count_table_17000000-17999999.parquet'),\n",
       " WindowsPath('data/5/count_table_18000000-18999999.parquet'),\n",
       " WindowsPath('data/5/count_table_19000000-19999999.parquet'),\n",
       " WindowsPath('data/5/count_table_2000000-2999999.parquet'),\n",
       " WindowsPath('data/5/count_table_20000000-20999999.parquet'),\n",
       " WindowsPath('data/5/count_table_21000000-21999999.parquet'),\n",
       " WindowsPath('data/5/count_table_22000000-22999999.parquet'),\n",
       " WindowsPath('data/5/count_table_23000000-23999999.parquet'),\n",
       " WindowsPath('data/5/count_table_24000000-24999999.parquet'),\n",
       " WindowsPath('data/5/count_table_25000000-25999999.parquet'),\n",
       " WindowsPath('data/5/count_table_26000000-26999999.parquet'),\n",
       " WindowsPath('data/5/count_table_27000000-27999999.parquet'),\n",
       " WindowsPath('data/5/count_table_28000000-28999999.parquet'),\n",
       " WindowsPath('data/5/count_table_29000000-29999999.parquet'),\n",
       " WindowsPath('data/5/count_table_3000000-3999999.parquet'),\n",
       " WindowsPath('data/5/count_table_4000000-4999999.parquet'),\n",
       " WindowsPath('data/5/count_table_5000000-5999999.parquet'),\n",
       " WindowsPath('data/5/count_table_6000000-6999999.parquet'),\n",
       " WindowsPath('data/5/count_table_7000000-7999999.parquet'),\n",
       " WindowsPath('data/5/count_table_8000000-8999999.parquet'),\n",
       " WindowsPath('data/5/count_table_9000000-9999999.parquet')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze space requirements\n",
    "generated_files = list(save_dir.rglob('*.parquet'))\n",
    "generated_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0c54d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442371415"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the number of tokens processed\n",
    "import json\n",
    "total_ngram_per_size_file = next(iter(save_dir.rglob('*.json')))\n",
    "with total_ngram_per_size_file.open('r') as f:\n",
    "    total_ngram_per_size = json.load(f)\n",
    "total_ngram_per_size\n",
    "n_tokens_processed = total_ngram_per_size['1']\n",
    "n_tokens_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d97eda07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(file: Path) -> int:\n",
    "    return file.stat().st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2604738a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165535"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_file = generated_files[0]\n",
    "get_file_size(example_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a9b805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721005352"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_parquet_file_size_in_bytes = sum(map(get_file_size, generated_files))\n",
    "total_parquet_file_size_in_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f6c284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parquet files total size: 687 MB\n"
     ]
    }
   ],
   "source": [
    "total_parquet_file_size_in_mb = total_parquet_file_size_in_bytes // (2 ** 20)\n",
    "print(f'parquet files total size: {total_parquet_file_size_in_mb} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddd894cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens processed: 442,371,415\n"
     ]
    }
   ],
   "source": [
    "print(f'tokens processed: {n_tokens_processed:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7378f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming linear growth in the number of tokens processed, which should be approximatlty correct:\n",
    "n_tokens_wikipedia =     24_000_000_000  # 24 Billion\n",
    "n_tokens_red_pijama = 1_200_000_000_000  # 1.2 Trillion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af734f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dataset_expected_space_bytes(n_tokens_in_dataset: int) -> int:\n",
    "    dataset_size_factor = n_tokens_in_dataset / n_tokens_processed\n",
    "    return total_parquet_file_size_in_bytes * dataset_size_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d03376fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected space for wikipedia dataset: 36.0 GB\n"
     ]
    }
   ],
   "source": [
    "wikipedia_expected_space_gb = compute_dataset_expected_space_bytes(n_tokens_wikipedia) // (2 ** 30)\n",
    "print(f'expected space for wikipedia dataset: {wikipedia_expected_space_gb} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "416f132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected space for RedPijama dataset: 1821.0 GB\n"
     ]
    }
   ],
   "source": [
    "red_pijama_expected_space_gb = compute_dataset_expected_space_bytes(n_tokens_red_pijama) // (2 ** 30)\n",
    "print(f'expected space for RedPijama dataset: {red_pijama_expected_space_gb} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d220233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-05-02 20:19:48,327 - src.count_ngrams_in_batches - INFO - Starting to count ngrams in batches\\n',\n",
       " \"2023-05-02 20:20:33,385 - src.count_ngrams_in_batches - INFO - started working on samples 20000000-20999999;memory (MB): {'total': 8066, 'used': 6084, 'available': 1982}\\n\",\n",
       " \"2023-05-02 20:20:46,091 - src.count_ngrams_in_batches - INFO - started working on samples 0-999999;memory (MB): {'total': 8066, 'used': 6681, 'available': 1385}\\n\",\n",
       " \"2023-05-02 20:20:46,233 - src.count_ngrams_in_batches - INFO - started working on samples 10000000-10999999;memory (MB): {'total': 8066, 'used': 6761, 'available': 1305}\\n\",\n",
       " \"2023-05-02 20:24:28,621 - src.count_ngrams_in_batches - INFO - finished samples 20000000 to 20999999;memory (MB): {'total': 8066, 'used': 7031, 'available': 1035};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:25:03,640 - src.count_ngrams_in_batches - INFO - finished samples 10000000 to 10999999;memory (MB): {'total': 8066, 'used': 7103, 'available': 963};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:25:05,101 - src.count_ngrams_in_batches - INFO - started working on samples 21000000-21999999;memory (MB): {'total': 8066, 'used': 7386, 'available': 680}\\n\",\n",
       " \"2023-05-02 20:25:07,862 - src.count_ngrams_in_batches - INFO - finished samples 0 to 999999;memory (MB): {'total': 8066, 'used': 7307, 'available': 759};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:25:16,076 - src.count_ngrams_in_batches - INFO - started working on samples 1000000-1999999;memory (MB): {'total': 8066, 'used': 4460, 'available': 3605}\\n\",\n",
       " \"2023-05-02 20:25:17,209 - src.count_ngrams_in_batches - INFO - started working on samples 11000000-11999999;memory (MB): {'total': 8066, 'used': 4473, 'available': 3593}\\n\",\n",
       " \"2023-05-02 20:29:02,849 - src.count_ngrams_in_batches - INFO - finished samples 21000000 to 21999999;memory (MB): {'total': 8066, 'used': 7489, 'available': 577};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:29:30,443 - src.count_ngrams_in_batches - INFO - finished samples 1000000 to 1999999;memory (MB): {'total': 8066, 'used': 7235, 'available': 830};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:29:34,810 - src.count_ngrams_in_batches - INFO - started working on samples 22000000-22999999;memory (MB): {'total': 8066, 'used': 7538, 'available': 528}\\n\",\n",
       " \"2023-05-02 20:29:35,990 - src.count_ngrams_in_batches - INFO - finished samples 11000000 to 11999999;memory (MB): {'total': 8066, 'used': 7489, 'available': 576};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:29:40,853 - src.count_ngrams_in_batches - INFO - started working on samples 2000000-2999999;memory (MB): {'total': 8066, 'used': 4548, 'available': 3517}\\n\",\n",
       " \"2023-05-02 20:29:43,936 - src.count_ngrams_in_batches - INFO - started working on samples 12000000-12999999;memory (MB): {'total': 8066, 'used': 4416, 'available': 3649}\\n\",\n",
       " \"2023-05-02 20:32:57,654 - src.count_ngrams_in_batches - INFO - finished samples 2000000 to 2999999;memory (MB): {'total': 8066, 'used': 7659, 'available': 407};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:33:11,587 - src.count_ngrams_in_batches - INFO - finished samples 22000000 to 22999999;memory (MB): {'total': 8066, 'used': 6891, 'available': 1174};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:33:14,967 - src.count_ngrams_in_batches - INFO - started working on samples 3000000-3999999;memory (MB): {'total': 8066, 'used': 6870, 'available': 1196}\\n\",\n",
       " \"2023-05-02 20:33:20,923 - src.count_ngrams_in_batches - INFO - started working on samples 23000000-23999999;memory (MB): {'total': 8066, 'used': 6882, 'available': 1184}\\n\",\n",
       " \"2023-05-02 20:33:26,068 - src.count_ngrams_in_batches - INFO - finished samples 12000000 to 12999999;memory (MB): {'total': 8066, 'used': 7093, 'available': 972};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:33:30,061 - src.count_ngrams_in_batches - INFO - started working on samples 13000000-13999999;memory (MB): {'total': 8066, 'used': 4249, 'available': 3816}\\n\",\n",
       " \"2023-05-02 20:36:41,591 - src.count_ngrams_in_batches - INFO - finished samples 3000000 to 3999999;memory (MB): {'total': 8066, 'used': 7548, 'available': 518};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:37:00,636 - src.count_ngrams_in_batches - INFO - finished samples 23000000 to 23999999;memory (MB): {'total': 8066, 'used': 7689, 'available': 377};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:37:06,940 - src.count_ngrams_in_batches - INFO - started working on samples 4000000-4999999;memory (MB): {'total': 8066, 'used': 7317, 'available': 749}\\n\",\n",
       " \"2023-05-02 20:37:11,676 - src.count_ngrams_in_batches - INFO - started working on samples 24000000-24999999;memory (MB): {'total': 8066, 'used': 6914, 'available': 1152}\\n\",\n",
       " \"2023-05-02 20:37:20,994 - src.count_ngrams_in_batches - INFO - finished samples 13000000 to 13999999;memory (MB): {'total': 8066, 'used': 7445, 'available': 621};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:37:25,070 - src.count_ngrams_in_batches - INFO - started working on samples 14000000-14999999;memory (MB): {'total': 8066, 'used': 4725, 'available': 3341}\\n\",\n",
       " \"2023-05-02 20:40:41,723 - src.count_ngrams_in_batches - INFO - finished samples 4000000 to 4999999;memory (MB): {'total': 8066, 'used': 7614, 'available': 452};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:41:15,644 - src.count_ngrams_in_batches - INFO - finished samples 24000000 to 24999999;memory (MB): {'total': 8066, 'used': 7147, 'available': 918};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:41:16,227 - src.count_ngrams_in_batches - INFO - started working on samples 5000000-5999999;memory (MB): {'total': 8066, 'used': 7284, 'available': 782}\\n\",\n",
       " \"2023-05-02 20:41:26,020 - src.count_ngrams_in_batches - INFO - finished samples 14000000 to 14999999;memory (MB): {'total': 8066, 'used': 6740, 'available': 1326};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:41:29,455 - src.count_ngrams_in_batches - INFO - started working on samples 25000000-25999999;memory (MB): {'total': 8066, 'used': 5000, 'available': 3066}\\n\",\n",
       " \"2023-05-02 20:41:32,393 - src.count_ngrams_in_batches - INFO - started working on samples 15000000-15999999;memory (MB): {'total': 8066, 'used': 4928, 'available': 3138}\\n\",\n",
       " \"2023-05-02 20:44:57,528 - src.count_ngrams_in_batches - INFO - finished samples 5000000 to 5999999;memory (MB): {'total': 8066, 'used': 7244, 'available': 822};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:45:11,479 - src.count_ngrams_in_batches - INFO - finished samples 25000000 to 25999999;memory (MB): {'total': 8066, 'used': 7261, 'available': 805};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:45:21,460 - src.count_ngrams_in_batches - INFO - started working on samples 6000000-6999999;memory (MB): {'total': 8066, 'used': 7249, 'available': 817}\\n\",\n",
       " \"2023-05-02 20:45:25,232 - src.count_ngrams_in_batches - INFO - started working on samples 26000000-26999999;memory (MB): {'total': 8066, 'used': 6610, 'available': 1456}\\n\",\n",
       " \"2023-05-02 20:45:28,831 - src.count_ngrams_in_batches - INFO - finished samples 15000000 to 15999999;memory (MB): {'total': 8066, 'used': 7010, 'available': 1056};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:45:33,475 - src.count_ngrams_in_batches - INFO - started working on samples 16000000-16999999;memory (MB): {'total': 8066, 'used': 4825, 'available': 3241}\\n\",\n",
       " \"2023-05-02 20:49:01,870 - src.count_ngrams_in_batches - INFO - finished samples 26000000 to 26999999;memory (MB): {'total': 8066, 'used': 7195, 'available': 871};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:49:06,633 - src.count_ngrams_in_batches - INFO - finished samples 6000000 to 6999999;memory (MB): {'total': 8066, 'used': 7430, 'available': 635};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:49:23,846 - src.count_ngrams_in_batches - INFO - started working on samples 27000000-27999999;memory (MB): {'total': 8066, 'used': 6436, 'available': 1629}\\n\",\n",
       " \"2023-05-02 20:49:24,913 - src.count_ngrams_in_batches - INFO - started working on samples 7000000-7999999;memory (MB): {'total': 8066, 'used': 6636, 'available': 1429}\\n\",\n",
       " \"2023-05-02 20:49:26,787 - src.count_ngrams_in_batches - INFO - finished samples 16000000 to 16999999;memory (MB): {'total': 8066, 'used': 6906, 'available': 1160};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:49:32,209 - src.count_ngrams_in_batches - INFO - started working on samples 17000000-17999999;memory (MB): {'total': 8066, 'used': 4892, 'available': 3173}\\n\",\n",
       " \"2023-05-02 20:53:08,504 - src.count_ngrams_in_batches - INFO - finished samples 17000000 to 17999999;memory (MB): {'total': 8066, 'used': 7735, 'available': 330};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:53:12,961 - src.count_ngrams_in_batches - INFO - finished samples 7000000 to 7999999;memory (MB): {'total': 8066, 'used': 7303, 'available': 763};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:53:14,348 - src.count_ngrams_in_batches - INFO - finished samples 27000000 to 27999999;memory (MB): {'total': 8066, 'used': 7239, 'available': 827};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:53:24,889 - src.count_ngrams_in_batches - INFO - started working on samples 18000000-18999999;memory (MB): {'total': 8066, 'used': 4696, 'available': 3370}\\n\",\n",
       " \"2023-05-02 20:53:25,696 - src.count_ngrams_in_batches - INFO - started working on samples 28000000-28999999;memory (MB): {'total': 8066, 'used': 4607, 'available': 3459}\\n\",\n",
       " \"2023-05-02 20:53:26,115 - src.count_ngrams_in_batches - INFO - started working on samples 8000000-8999999;memory (MB): {'total': 8066, 'used': 4678, 'available': 3388}\\n\",\n",
       " \"2023-05-02 20:56:49,250 - src.count_ngrams_in_batches - INFO - finished samples 18000000 to 18999999;memory (MB): {'total': 8066, 'used': 7173, 'available': 893};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:57:18,844 - src.count_ngrams_in_batches - INFO - finished samples 28000000 to 28999999;memory (MB): {'total': 8066, 'used': 7205, 'available': 861};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:57:18,906 - src.count_ngrams_in_batches - INFO - finished samples 8000000 to 8999999;memory (MB): {'total': 8066, 'used': 7211, 'available': 855};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 20:57:21,048 - src.count_ngrams_in_batches - INFO - started working on samples 19000000-19999999;memory (MB): {'total': 8066, 'used': 7285, 'available': 781}\\n\",\n",
       " \"2023-05-02 20:57:27,229 - src.count_ngrams_in_batches - INFO - started working on samples 9000000-9999999;memory (MB): {'total': 8066, 'used': 4967, 'available': 3099}\\n\",\n",
       " \"2023-05-02 20:57:27,537 - src.count_ngrams_in_batches - INFO - started working on samples 29000000-29999999;memory (MB): {'total': 8066, 'used': 5064, 'available': 3002}\\n\",\n",
       " \"2023-05-02 21:00:42,610 - src.count_ngrams_in_batches - INFO - finished samples 9000000 to 9999999;memory (MB): {'total': 8066, 'used': 7532, 'available': 533};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 21:01:04,852 - src.count_ngrams_in_batches - INFO - finished samples 19000000 to 19999999;memory (MB): {'total': 8066, 'used': 7357, 'available': 709};counter size (MB): 0\\n\",\n",
       " \"2023-05-02 21:01:10,406 - src.count_ngrams_in_batches - INFO - finished samples 29000000 to 29999999;memory (MB): {'total': 8066, 'used': 7499, 'available': 567};counter size (MB): 0\\n\",\n",
       " '2023-05-02 21:01:47,204 - src.count_ngrams_in_batches - INFO - Finished counting ngrams in batches\\n',\n",
       " '2023-05-02 21:01:47,962 - src.aggregate_batch_ngram_counts - INFO - aggregate batch ngram counts - start\\n',\n",
       " '2023-05-02 21:01:47,962 - src.aggregate_batch_ngram_counts - INFO - aggregating ngrams of size 1\\n',\n",
       " '2023-05-02 21:01:47,962 - src.aggregate_batch_ngram_counts - INFO - creating new table. executing query:\\n',\n",
       " 'CREATE OR REPLACE TABLE ngram_of_size_1_counts_table(token_0 UINTEGER, count UINTEGER, PRIMARY KEY(token_0));\\n',\n",
       " '2023-05-02 21:01:48,067 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_0-999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:49,348 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_0-999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:49,356 - src.aggregate_batch_ngram_counts - INFO - table size: 21237\\n',\n",
       " '2023-05-02 21:01:49,373 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_1000000-1999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:49,784 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_1000000-1999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:49,786 - src.aggregate_batch_ngram_counts - INFO - table size: 22548\\n',\n",
       " '2023-05-02 21:01:49,808 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_10000000-10999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:50,331 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_10000000-10999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:50,332 - src.aggregate_batch_ngram_counts - INFO - table size: 24469\\n',\n",
       " '2023-05-02 21:01:50,360 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_11000000-11999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:50,921 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_11000000-11999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:50,922 - src.aggregate_batch_ngram_counts - INFO - table size: 25505\\n',\n",
       " '2023-05-02 21:01:50,938 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_12000000-12999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:51,623 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_12000000-12999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:51,624 - src.aggregate_batch_ngram_counts - INFO - table size: 25992\\n',\n",
       " '2023-05-02 21:01:51,644 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_13000000-13999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:52,480 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_13000000-13999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:52,481 - src.aggregate_batch_ngram_counts - INFO - table size: 26267\\n',\n",
       " '2023-05-02 21:01:52,493 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_14000000-14999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:53,363 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_14000000-14999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:53,365 - src.aggregate_batch_ngram_counts - INFO - table size: 26483\\n',\n",
       " '2023-05-02 21:01:53,378 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_15000000-15999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:54,034 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_15000000-15999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:54,035 - src.aggregate_batch_ngram_counts - INFO - table size: 26532\\n',\n",
       " '2023-05-02 21:01:54,049 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_16000000-16999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:54,728 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_16000000-16999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:54,729 - src.aggregate_batch_ngram_counts - INFO - table size: 26594\\n',\n",
       " '2023-05-02 21:01:54,742 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_17000000-17999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:55,392 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_17000000-17999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:55,393 - src.aggregate_batch_ngram_counts - INFO - table size: 26662\\n',\n",
       " '2023-05-02 21:01:55,408 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_18000000-18999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:56,030 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_18000000-18999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:56,033 - src.aggregate_batch_ngram_counts - INFO - table size: 26714\\n',\n",
       " '2023-05-02 21:01:56,045 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_19000000-19999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:56,641 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_19000000-19999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:56,644 - src.aggregate_batch_ngram_counts - INFO - table size: 26913\\n',\n",
       " '2023-05-02 21:01:56,658 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_2000000-2999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:57,144 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_2000000-2999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:57,145 - src.aggregate_batch_ngram_counts - INFO - table size: 26920\\n',\n",
       " '2023-05-02 21:01:57,159 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_20000000-20999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:57,749 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_20000000-20999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:57,751 - src.aggregate_batch_ngram_counts - INFO - table size: 27040\\n',\n",
       " '2023-05-02 21:01:57,762 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_21000000-21999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:58,439 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_21000000-21999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:58,440 - src.aggregate_batch_ngram_counts - INFO - table size: 27104\\n',\n",
       " '2023-05-02 21:01:58,452 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_22000000-22999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:01:59,254 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_22000000-22999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:01:59,257 - src.aggregate_batch_ngram_counts - INFO - table size: 27179\\n',\n",
       " '2023-05-02 21:01:59,272 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_23000000-23999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:00,030 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_23000000-23999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:00,031 - src.aggregate_batch_ngram_counts - INFO - table size: 27201\\n',\n",
       " '2023-05-02 21:02:00,045 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_24000000-24999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:00,602 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_24000000-24999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:00,606 - src.aggregate_batch_ngram_counts - INFO - table size: 27203\\n',\n",
       " '2023-05-02 21:02:00,632 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_25000000-25999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:01,189 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_25000000-25999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:01,190 - src.aggregate_batch_ngram_counts - INFO - table size: 27208\\n',\n",
       " '2023-05-02 21:02:01,215 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_26000000-26999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:01,768 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_26000000-26999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:01,771 - src.aggregate_batch_ngram_counts - INFO - table size: 27210\\n',\n",
       " '2023-05-02 21:02:01,790 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_27000000-27999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:02,361 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_27000000-27999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:02,366 - src.aggregate_batch_ngram_counts - INFO - table size: 27214\\n',\n",
       " '2023-05-02 21:02:02,384 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_28000000-28999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:03,307 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_28000000-28999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:03,308 - src.aggregate_batch_ngram_counts - INFO - table size: 27221\\n',\n",
       " '2023-05-02 21:02:03,318 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_29000000-29999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:03,915 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_29000000-29999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:03,916 - src.aggregate_batch_ngram_counts - INFO - table size: 27230\\n',\n",
       " '2023-05-02 21:02:03,929 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_3000000-3999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:04,469 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_3000000-3999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:04,472 - src.aggregate_batch_ngram_counts - INFO - table size: 27234\\n',\n",
       " '2023-05-02 21:02:04,485 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_4000000-4999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:05,011 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_4000000-4999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:05,013 - src.aggregate_batch_ngram_counts - INFO - table size: 27237\\n',\n",
       " '2023-05-02 21:02:05,026 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_5000000-5999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:05,558 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_5000000-5999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:05,559 - src.aggregate_batch_ngram_counts - INFO - table size: 27240\\n',\n",
       " '2023-05-02 21:02:05,572 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_6000000-6999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:06,128 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_6000000-6999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:06,130 - src.aggregate_batch_ngram_counts - INFO - table size: 27240\\n',\n",
       " '2023-05-02 21:02:06,142 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_7000000-7999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:06,656 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_7000000-7999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:06,658 - src.aggregate_batch_ngram_counts - INFO - table size: 27243\\n',\n",
       " '2023-05-02 21:02:06,675 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_8000000-8999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:07,166 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_8000000-8999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:07,167 - src.aggregate_batch_ngram_counts - INFO - table size: 27246\\n',\n",
       " '2023-05-02 21:02:07,186 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_9000000-9999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_1_counts_table SELECT token_0, count FROM table_to_insert ON CONFLICT (token_0) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:07,660 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\1\\\\count_table_9000000-9999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:07,661 - src.aggregate_batch_ngram_counts - INFO - table size: 27247\\n',\n",
       " '2023-05-02 21:02:07,661 - src.aggregate_batch_ngram_counts - INFO - aggregating ngrams of size 2\\n',\n",
       " '2023-05-02 21:02:07,661 - src.aggregate_batch_ngram_counts - INFO - creating new table. executing query:\\n',\n",
       " 'CREATE OR REPLACE TABLE ngram_of_size_2_counts_table(token_0 UINTEGER, token_1 UINTEGER, count UINTEGER, PRIMARY KEY(token_0, token_1));\\n',\n",
       " '2023-05-02 21:02:07,680 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_0-999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:08,947 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_0-999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:08,951 - src.aggregate_batch_ngram_counts - INFO - table size: 540365\\n',\n",
       " '2023-05-02 21:02:08,988 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_1000000-1999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:15,406 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_1000000-1999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:15,407 - src.aggregate_batch_ngram_counts - INFO - table size: 721838\\n',\n",
       " '2023-05-02 21:02:15,420 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_10000000-10999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:25,541 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_10000000-10999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:25,546 - src.aggregate_batch_ngram_counts - INFO - table size: 948302\\n',\n",
       " '2023-05-02 21:02:25,586 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_11000000-11999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:37,229 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_11000000-11999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:37,231 - src.aggregate_batch_ngram_counts - INFO - table size: 1196961\\n',\n",
       " '2023-05-02 21:02:37,245 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_12000000-12999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:02:50,880 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_12000000-12999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:02:50,882 - src.aggregate_batch_ngram_counts - INFO - table size: 1388751\\n',\n",
       " '2023-05-02 21:02:50,918 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_13000000-13999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:03:04,912 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_13000000-13999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:03:04,919 - src.aggregate_batch_ngram_counts - INFO - table size: 1545151\\n',\n",
       " '2023-05-02 21:03:04,962 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_14000000-14999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:03:19,039 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_14000000-14999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:03:19,042 - src.aggregate_batch_ngram_counts - INFO - table size: 1676782\\n',\n",
       " '2023-05-02 21:03:19,088 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_15000000-15999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:03:32,482 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_15000000-15999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:03:32,485 - src.aggregate_batch_ngram_counts - INFO - table size: 1795067\\n',\n",
       " '2023-05-02 21:03:32,497 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_16000000-16999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:03:47,437 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_16000000-16999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:03:47,444 - src.aggregate_batch_ngram_counts - INFO - table size: 1899935\\n',\n",
       " '2023-05-02 21:03:47,467 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_17000000-17999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:04:02,679 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_17000000-17999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:04:02,683 - src.aggregate_batch_ngram_counts - INFO - table size: 1986254\\n',\n",
       " '2023-05-02 21:04:02,704 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_18000000-18999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:04:17,938 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_18000000-18999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:04:17,948 - src.aggregate_batch_ngram_counts - INFO - table size: 2065682\\n',\n",
       " '2023-05-02 21:04:17,967 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_19000000-19999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:04:34,525 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_19000000-19999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:04:34,530 - src.aggregate_batch_ngram_counts - INFO - table size: 2196072\\n',\n",
       " '2023-05-02 21:04:34,551 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_2000000-2999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:04:48,157 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_2000000-2999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:04:48,163 - src.aggregate_batch_ngram_counts - INFO - table size: 2255702\\n',\n",
       " '2023-05-02 21:04:48,187 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_20000000-20999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:05:06,406 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_20000000-20999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:05:06,411 - src.aggregate_batch_ngram_counts - INFO - table size: 2349645\\n',\n",
       " '2023-05-02 21:05:06,438 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_21000000-21999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:05:23,777 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_21000000-21999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:05:23,783 - src.aggregate_batch_ngram_counts - INFO - table size: 2434871\\n',\n",
       " '2023-05-02 21:05:23,803 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_22000000-22999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:05:40,519 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_22000000-22999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:05:40,524 - src.aggregate_batch_ngram_counts - INFO - table size: 2530147\\n',\n",
       " '2023-05-02 21:05:40,545 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_23000000-23999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:06:07,248 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_23000000-23999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:06:07,250 - src.aggregate_batch_ngram_counts - INFO - table size: 2578845\\n',\n",
       " '2023-05-02 21:06:07,263 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_24000000-24999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:06:26,469 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_24000000-24999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:06:26,472 - src.aggregate_batch_ngram_counts - INFO - table size: 2642123\\n',\n",
       " '2023-05-02 21:06:26,484 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_25000000-25999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:06:43,620 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_25000000-25999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:06:43,625 - src.aggregate_batch_ngram_counts - INFO - table size: 2678054\\n',\n",
       " '2023-05-02 21:06:43,648 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_26000000-26999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:07:01,144 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_26000000-26999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:07:01,147 - src.aggregate_batch_ngram_counts - INFO - table size: 2731305\\n',\n",
       " '2023-05-02 21:07:01,158 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_27000000-27999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:07:18,125 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_27000000-27999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:07:18,134 - src.aggregate_batch_ngram_counts - INFO - table size: 2784671\\n',\n",
       " '2023-05-02 21:07:18,189 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_28000000-28999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:07:36,861 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_28000000-28999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:07:36,865 - src.aggregate_batch_ngram_counts - INFO - table size: 2844103\\n',\n",
       " '2023-05-02 21:07:36,879 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_29000000-29999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:07:52,554 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_29000000-29999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:07:52,560 - src.aggregate_batch_ngram_counts - INFO - table size: 2890842\\n',\n",
       " '2023-05-02 21:07:52,584 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_3000000-3999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:08:10,106 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_3000000-3999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:08:10,113 - src.aggregate_batch_ngram_counts - INFO - table size: 2913879\\n',\n",
       " '2023-05-02 21:08:10,134 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_4000000-4999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:08:30,656 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_4000000-4999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:08:30,664 - src.aggregate_batch_ngram_counts - INFO - table size: 2959034\\n',\n",
       " '2023-05-02 21:08:30,681 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_5000000-5999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:08:52,401 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_5000000-5999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:08:52,408 - src.aggregate_batch_ngram_counts - INFO - table size: 2981900\\n',\n",
       " '2023-05-02 21:08:52,431 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_6000000-6999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:09:10,045 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_6000000-6999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:09:10,050 - src.aggregate_batch_ngram_counts - INFO - table size: 3025732\\n',\n",
       " '2023-05-02 21:09:10,072 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_7000000-7999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:09:27,882 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_7000000-7999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:09:27,889 - src.aggregate_batch_ngram_counts - INFO - table size: 3040573\\n',\n",
       " '2023-05-02 21:09:27,913 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_8000000-8999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:09:44,294 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_8000000-8999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:09:44,303 - src.aggregate_batch_ngram_counts - INFO - table size: 3076749\\n',\n",
       " '2023-05-02 21:09:44,319 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_9000000-9999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_2_counts_table SELECT token_0, token_1, count FROM table_to_insert ON CONFLICT (token_0, token_1) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:10:00,241 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\2\\\\count_table_9000000-9999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:10:00,247 - src.aggregate_batch_ngram_counts - INFO - table size: 3096906\\n',\n",
       " '2023-05-02 21:10:00,248 - src.aggregate_batch_ngram_counts - INFO - aggregating ngrams of size 3\\n',\n",
       " '2023-05-02 21:10:00,248 - src.aggregate_batch_ngram_counts - INFO - creating new table. executing query:\\n',\n",
       " 'CREATE OR REPLACE TABLE ngram_of_size_3_counts_table(token_0 UINTEGER, token_1 UINTEGER, token_2 UINTEGER, count UINTEGER, PRIMARY KEY(token_0, token_1, token_2));\\n',\n",
       " '2023-05-02 21:10:00,322 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_0-999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:10:06,104 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_0-999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:10:06,111 - src.aggregate_batch_ngram_counts - INFO - table size: 1178247\\n',\n",
       " '2023-05-02 21:10:06,147 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_1000000-1999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:10:25,709 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_1000000-1999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:10:25,714 - src.aggregate_batch_ngram_counts - INFO - table size: 1702623\\n',\n",
       " '2023-05-02 21:10:25,736 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_10000000-10999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:10:51,867 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_10000000-10999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:10:51,870 - src.aggregate_batch_ngram_counts - INFO - table size: 2279980\\n',\n",
       " '2023-05-02 21:10:51,889 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_11000000-11999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:11:20,027 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_11000000-11999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:11:20,035 - src.aggregate_batch_ngram_counts - INFO - table size: 2879361\\n',\n",
       " '2023-05-02 21:11:20,052 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_12000000-12999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:11:49,174 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_12000000-12999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:11:49,182 - src.aggregate_batch_ngram_counts - INFO - table size: 3356138\\n',\n",
       " '2023-05-02 21:11:49,224 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_13000000-13999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:12:23,291 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_13000000-13999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:12:23,295 - src.aggregate_batch_ngram_counts - INFO - table size: 3781439\\n',\n",
       " '2023-05-02 21:12:23,311 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_14000000-14999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:12:53,350 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_14000000-14999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:12:53,356 - src.aggregate_batch_ngram_counts - INFO - table size: 4185163\\n',\n",
       " '2023-05-02 21:12:53,361 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_15000000-15999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:13:22,891 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_15000000-15999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:13:22,900 - src.aggregate_batch_ngram_counts - INFO - table size: 4579453\\n',\n",
       " '2023-05-02 21:13:22,905 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_16000000-16999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:13:54,211 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_16000000-16999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:13:54,219 - src.aggregate_batch_ngram_counts - INFO - table size: 4888207\\n',\n",
       " '2023-05-02 21:13:54,223 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_17000000-17999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:14:25,554 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_17000000-17999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:14:25,563 - src.aggregate_batch_ngram_counts - INFO - table size: 5159059\\n',\n",
       " '2023-05-02 21:14:25,567 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_18000000-18999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:14:58,304 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_18000000-18999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:14:58,312 - src.aggregate_batch_ngram_counts - INFO - table size: 5409262\\n',\n",
       " '2023-05-02 21:14:58,316 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_19000000-19999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:15:32,373 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_19000000-19999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:15:32,381 - src.aggregate_batch_ngram_counts - INFO - table size: 5798797\\n',\n",
       " '2023-05-02 21:15:32,397 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_2000000-2999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:16:03,846 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_2000000-2999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:16:03,855 - src.aggregate_batch_ngram_counts - INFO - table size: 6018193\\n',\n",
       " '2023-05-02 21:16:03,874 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_20000000-20999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:16:40,965 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_20000000-20999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:16:40,978 - src.aggregate_batch_ngram_counts - INFO - table size: 6286424\\n',\n",
       " '2023-05-02 21:16:41,007 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_21000000-21999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:17:18,288 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_21000000-21999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:17:18,297 - src.aggregate_batch_ngram_counts - INFO - table size: 6534423\\n',\n",
       " '2023-05-02 21:17:18,315 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_22000000-22999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:17:51,738 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_22000000-22999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:17:51,748 - src.aggregate_batch_ngram_counts - INFO - table size: 6821796\\n',\n",
       " '2023-05-02 21:17:51,766 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_23000000-23999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:18:27,252 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_23000000-23999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:18:27,259 - src.aggregate_batch_ngram_counts - INFO - table size: 6991591\\n',\n",
       " '2023-05-02 21:18:27,275 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_24000000-24999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:19:02,589 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_24000000-24999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:19:02,599 - src.aggregate_batch_ngram_counts - INFO - table size: 7230935\\n',\n",
       " '2023-05-02 21:19:02,603 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_25000000-25999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:19:38,452 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_25000000-25999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:19:38,464 - src.aggregate_batch_ngram_counts - INFO - table size: 7366452\\n',\n",
       " '2023-05-02 21:19:38,468 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_26000000-26999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:20:13,223 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_26000000-26999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:20:13,234 - src.aggregate_batch_ngram_counts - INFO - table size: 7581032\\n',\n",
       " '2023-05-02 21:20:13,237 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_27000000-27999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:20:48,628 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_27000000-27999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:20:48,639 - src.aggregate_batch_ngram_counts - INFO - table size: 7783996\\n',\n",
       " '2023-05-02 21:20:48,644 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_28000000-28999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:21:24,698 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_28000000-28999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:21:24,708 - src.aggregate_batch_ngram_counts - INFO - table size: 8008590\\n',\n",
       " '2023-05-02 21:21:24,712 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_29000000-29999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:21:59,491 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_29000000-29999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:21:59,502 - src.aggregate_batch_ngram_counts - INFO - table size: 8183178\\n',\n",
       " '2023-05-02 21:21:59,517 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_3000000-3999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:22:35,886 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_3000000-3999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:22:35,898 - src.aggregate_batch_ngram_counts - INFO - table size: 8283031\\n',\n",
       " '2023-05-02 21:22:35,913 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_4000000-4999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:23:13,293 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_4000000-4999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:23:13,303 - src.aggregate_batch_ngram_counts - INFO - table size: 8469418\\n',\n",
       " '2023-05-02 21:23:13,306 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_5000000-5999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:23:52,666 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_5000000-5999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:23:52,680 - src.aggregate_batch_ngram_counts - INFO - table size: 8569115\\n',\n",
       " '2023-05-02 21:23:52,685 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_6000000-6999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:24:29,400 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_6000000-6999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:24:29,410 - src.aggregate_batch_ngram_counts - INFO - table size: 8740090\\n',\n",
       " '2023-05-02 21:24:29,414 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_7000000-7999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:25:07,843 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_7000000-7999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:25:07,854 - src.aggregate_batch_ngram_counts - INFO - table size: 8807750\\n',\n",
       " '2023-05-02 21:25:07,857 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_8000000-8999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:25:44,923 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_8000000-8999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:25:44,936 - src.aggregate_batch_ngram_counts - INFO - table size: 8941384\\n',\n",
       " '2023-05-02 21:25:44,941 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_9000000-9999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_3_counts_table SELECT token_0, token_1, token_2, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:26:19,756 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\3\\\\count_table_9000000-9999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:26:19,762 - src.aggregate_batch_ngram_counts - INFO - table size: 9034649\\n',\n",
       " '2023-05-02 21:26:19,763 - src.aggregate_batch_ngram_counts - INFO - aggregating ngrams of size 4\\n',\n",
       " '2023-05-02 21:26:19,763 - src.aggregate_batch_ngram_counts - INFO - creating new table. executing query:\\n',\n",
       " 'CREATE OR REPLACE TABLE ngram_of_size_4_counts_table(token_0 UINTEGER, token_1 UINTEGER, token_2 UINTEGER, token_3 UINTEGER, count UINTEGER, PRIMARY KEY(token_0, token_1, token_2, token_3));\\n',\n",
       " '2023-05-02 21:26:19,784 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_0-999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:26:30,449 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_0-999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:26:30,456 - src.aggregate_batch_ngram_counts - INFO - table size: 1108812\\n',\n",
       " '2023-05-02 21:26:30,482 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_1000000-1999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:26:48,105 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_1000000-1999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:26:48,111 - src.aggregate_batch_ngram_counts - INFO - table size: 1701383\\n',\n",
       " '2023-05-02 21:26:48,157 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_10000000-10999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:27:08,195 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_10000000-10999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:27:08,201 - src.aggregate_batch_ngram_counts - INFO - table size: 2318267\\n',\n",
       " '2023-05-02 21:27:08,220 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_11000000-11999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:27:27,499 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_11000000-11999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:27:27,506 - src.aggregate_batch_ngram_counts - INFO - table size: 2848607\\n',\n",
       " '2023-05-02 21:27:27,526 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_12000000-12999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:27:48,018 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_12000000-12999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:27:48,023 - src.aggregate_batch_ngram_counts - INFO - table size: 3292245\\n',\n",
       " '2023-05-02 21:27:48,039 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_13000000-13999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:28:09,855 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_13000000-13999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:28:09,865 - src.aggregate_batch_ngram_counts - INFO - table size: 3730650\\n',\n",
       " '2023-05-02 21:28:09,880 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_14000000-14999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:28:33,401 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_14000000-14999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:28:33,405 - src.aggregate_batch_ngram_counts - INFO - table size: 4215131\\n',\n",
       " '2023-05-02 21:28:33,408 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_15000000-15999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:28:57,900 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_15000000-15999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:28:57,909 - src.aggregate_batch_ngram_counts - INFO - table size: 4685636\\n',\n",
       " '2023-05-02 21:28:57,916 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_16000000-16999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:29:24,401 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_16000000-16999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:29:24,411 - src.aggregate_batch_ngram_counts - INFO - table size: 5016935\\n',\n",
       " '2023-05-02 21:29:24,415 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_17000000-17999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:29:49,362 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_17000000-17999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:29:49,370 - src.aggregate_batch_ngram_counts - INFO - table size: 5326338\\n',\n",
       " '2023-05-02 21:29:49,375 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_18000000-18999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:30:14,166 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_18000000-18999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:30:14,176 - src.aggregate_batch_ngram_counts - INFO - table size: 5603044\\n',\n",
       " '2023-05-02 21:30:14,181 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_19000000-19999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:30:40,232 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_19000000-19999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:30:40,243 - src.aggregate_batch_ngram_counts - INFO - table size: 6076119\\n',\n",
       " '2023-05-02 21:30:40,409 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_2000000-2999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:31:09,687 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_2000000-2999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:31:09,696 - src.aggregate_batch_ngram_counts - INFO - table size: 6387416\\n',\n",
       " '2023-05-02 21:31:09,714 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_20000000-20999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:31:39,355 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_20000000-20999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:31:39,360 - src.aggregate_batch_ngram_counts - INFO - table size: 6663457\\n',\n",
       " '2023-05-02 21:31:39,371 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_21000000-21999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:32:07,643 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_21000000-21999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:32:07,652 - src.aggregate_batch_ngram_counts - INFO - table size: 6920287\\n',\n",
       " '2023-05-02 21:32:07,667 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_22000000-22999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:32:34,448 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_22000000-22999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:32:34,458 - src.aggregate_batch_ngram_counts - INFO - table size: 7251726\\n',\n",
       " '2023-05-02 21:32:34,482 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_23000000-23999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:33:03,657 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_23000000-23999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:33:03,665 - src.aggregate_batch_ngram_counts - INFO - table size: 7470095\\n',\n",
       " '2023-05-02 21:33:03,678 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_24000000-24999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:33:33,821 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_24000000-24999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:33:33,826 - src.aggregate_batch_ngram_counts - INFO - table size: 7790693\\n',\n",
       " '2023-05-02 21:33:33,832 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_25000000-25999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:34:04,454 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_25000000-25999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:34:04,464 - src.aggregate_batch_ngram_counts - INFO - table size: 7964958\\n',\n",
       " '2023-05-02 21:34:04,466 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_26000000-26999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:34:35,148 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_26000000-26999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:34:35,153 - src.aggregate_batch_ngram_counts - INFO - table size: 8274776\\n',\n",
       " '2023-05-02 21:34:35,156 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_27000000-27999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:35:06,919 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_27000000-27999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:35:06,929 - src.aggregate_batch_ngram_counts - INFO - table size: 8559194\\n',\n",
       " '2023-05-02 21:35:06,933 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_28000000-28999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:35:37,548 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_28000000-28999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:35:37,559 - src.aggregate_batch_ngram_counts - INFO - table size: 8864536\\n',\n",
       " '2023-05-02 21:35:37,564 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_29000000-29999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:36:09,104 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_29000000-29999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:36:09,116 - src.aggregate_batch_ngram_counts - INFO - table size: 9106338\\n',\n",
       " '2023-05-02 21:36:09,135 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_3000000-3999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:36:41,245 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_3000000-3999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:36:41,257 - src.aggregate_batch_ngram_counts - INFO - table size: 9256266\\n',\n",
       " '2023-05-02 21:36:41,269 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_4000000-4999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:37:14,545 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_4000000-4999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:37:14,557 - src.aggregate_batch_ngram_counts - INFO - table size: 9529910\\n',\n",
       " '2023-05-02 21:37:14,561 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_5000000-5999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:37:49,405 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_5000000-5999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:37:49,415 - src.aggregate_batch_ngram_counts - INFO - table size: 9687241\\n',\n",
       " '2023-05-02 21:37:49,417 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_6000000-6999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:38:23,172 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_6000000-6999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:38:23,182 - src.aggregate_batch_ngram_counts - INFO - table size: 9947695\\n',\n",
       " '2023-05-02 21:38:23,186 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_7000000-7999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:38:58,718 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_7000000-7999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:38:58,730 - src.aggregate_batch_ngram_counts - INFO - table size: 10057877\\n',\n",
       " '2023-05-02 21:38:58,735 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_8000000-8999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:39:34,052 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_8000000-8999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:39:34,064 - src.aggregate_batch_ngram_counts - INFO - table size: 10241072\\n',\n",
       " '2023-05-02 21:39:34,067 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_9000000-9999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_4_counts_table SELECT token_0, token_1, token_2, token_3, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:40:07,136 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\4\\\\count_table_9000000-9999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:40:07,146 - src.aggregate_batch_ngram_counts - INFO - table size: 10395237\\n',\n",
       " '2023-05-02 21:40:07,146 - src.aggregate_batch_ngram_counts - INFO - aggregating ngrams of size 5\\n',\n",
       " '2023-05-02 21:40:07,147 - src.aggregate_batch_ngram_counts - INFO - creating new table. executing query:\\n',\n",
       " 'CREATE OR REPLACE TABLE ngram_of_size_5_counts_table(token_0 UINTEGER, token_1 UINTEGER, token_2 UINTEGER, token_3 UINTEGER, token_4 UINTEGER, count UINTEGER, PRIMARY KEY(token_0, token_1, token_2, token_3, token_4));\\n',\n",
       " '2023-05-02 21:40:07,195 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_0-999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:40:23,659 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_0-999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:40:23,662 - src.aggregate_batch_ngram_counts - INFO - table size: 737756\\n',\n",
       " '2023-05-02 21:40:23,679 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_1000000-1999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:40:44,374 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_1000000-1999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:40:44,381 - src.aggregate_batch_ngram_counts - INFO - table size: 1178270\\n',\n",
       " '2023-05-02 21:40:44,399 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_10000000-10999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:41:10,072 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_10000000-10999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:41:10,078 - src.aggregate_batch_ngram_counts - INFO - table size: 1640728\\n',\n",
       " '2023-05-02 21:41:10,094 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_11000000-11999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:41:28,522 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_11000000-11999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:41:28,529 - src.aggregate_batch_ngram_counts - INFO - table size: 1939222\\n',\n",
       " '2023-05-02 21:41:28,545 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_12000000-12999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:41:48,279 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_12000000-12999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:41:48,284 - src.aggregate_batch_ngram_counts - INFO - table size: 2203594\\n',\n",
       " '2023-05-02 21:41:48,303 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_13000000-13999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:42:08,904 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_13000000-13999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:42:08,911 - src.aggregate_batch_ngram_counts - INFO - table size: 2512142\\n',\n",
       " '2023-05-02 21:42:08,933 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_14000000-14999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:42:31,624 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_14000000-14999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:42:31,632 - src.aggregate_batch_ngram_counts - INFO - table size: 2919557\\n',\n",
       " '2023-05-02 21:42:31,636 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_15000000-15999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:42:56,336 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_15000000-15999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:42:56,343 - src.aggregate_batch_ngram_counts - INFO - table size: 3286634\\n',\n",
       " '2023-05-02 21:42:56,349 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_16000000-16999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:43:18,940 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_16000000-16999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:43:18,946 - src.aggregate_batch_ngram_counts - INFO - table size: 3514233\\n',\n",
       " '2023-05-02 21:43:18,951 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_17000000-17999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:43:41,489 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_17000000-17999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:43:41,496 - src.aggregate_batch_ngram_counts - INFO - table size: 3734922\\n',\n",
       " '2023-05-02 21:43:41,500 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_18000000-18999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:44:05,747 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_18000000-18999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:44:05,754 - src.aggregate_batch_ngram_counts - INFO - table size: 3915757\\n',\n",
       " '2023-05-02 21:44:05,758 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_19000000-19999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:44:28,886 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_19000000-19999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:44:28,893 - src.aggregate_batch_ngram_counts - INFO - table size: 4321488\\n',\n",
       " '2023-05-02 21:44:28,917 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_2000000-2999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:44:55,065 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_2000000-2999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:44:55,073 - src.aggregate_batch_ngram_counts - INFO - table size: 4605783\\n',\n",
       " '2023-05-02 21:44:55,363 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_20000000-20999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:45:19,731 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_20000000-20999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:45:19,740 - src.aggregate_batch_ngram_counts - INFO - table size: 4780576\\n',\n",
       " '2023-05-02 21:45:19,756 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_21000000-21999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:45:44,043 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_21000000-21999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:45:44,053 - src.aggregate_batch_ngram_counts - INFO - table size: 4947067\\n',\n",
       " '2023-05-02 21:45:44,070 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_22000000-22999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:46:11,346 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_22000000-22999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:46:11,356 - src.aggregate_batch_ngram_counts - INFO - table size: 5201001\\n',\n",
       " '2023-05-02 21:46:11,372 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_23000000-23999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:46:37,253 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_23000000-23999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:46:37,257 - src.aggregate_batch_ngram_counts - INFO - table size: 5380466\\n',\n",
       " '2023-05-02 21:46:37,272 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_24000000-24999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:47:05,159 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_24000000-24999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:47:05,166 - src.aggregate_batch_ngram_counts - INFO - table size: 5642526\\n',\n",
       " '2023-05-02 21:47:05,170 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_25000000-25999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:47:32,655 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_25000000-25999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:47:32,664 - src.aggregate_batch_ngram_counts - INFO - table size: 5782874\\n',\n",
       " '2023-05-02 21:47:32,668 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_26000000-26999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:48:02,820 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_26000000-26999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:48:02,829 - src.aggregate_batch_ngram_counts - INFO - table size: 6064085\\n',\n",
       " '2023-05-02 21:48:02,833 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_27000000-27999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:48:32,873 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_27000000-27999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:48:32,892 - src.aggregate_batch_ngram_counts - INFO - table size: 6315594\\n',\n",
       " '2023-05-02 21:48:32,923 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_28000000-28999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:49:01,126 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_28000000-28999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:49:01,136 - src.aggregate_batch_ngram_counts - INFO - table size: 6591608\\n',\n",
       " '2023-05-02 21:49:01,140 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_29000000-29999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:49:30,524 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_29000000-29999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:49:30,531 - src.aggregate_batch_ngram_counts - INFO - table size: 6803734\\n',\n",
       " '2023-05-02 21:49:30,552 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_3000000-3999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:50:01,978 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_3000000-3999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:50:01,988 - src.aggregate_batch_ngram_counts - INFO - table size: 6943549\\n',\n",
       " '2023-05-02 21:50:02,002 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_4000000-4999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:50:33,757 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_4000000-4999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:50:33,762 - src.aggregate_batch_ngram_counts - INFO - table size: 7194769\\n',\n",
       " '2023-05-02 21:50:33,765 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_5000000-5999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:51:06,150 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_5000000-5999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:51:06,160 - src.aggregate_batch_ngram_counts - INFO - table size: 7346292\\n',\n",
       " '2023-05-02 21:51:06,163 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_6000000-6999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:51:36,614 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_6000000-6999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:51:36,623 - src.aggregate_batch_ngram_counts - INFO - table size: 7599410\\n',\n",
       " '2023-05-02 21:51:36,626 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_7000000-7999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:52:08,132 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_7000000-7999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:52:08,142 - src.aggregate_batch_ngram_counts - INFO - table size: 7705731\\n',\n",
       " '2023-05-02 21:52:08,148 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_8000000-8999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:52:38,756 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_8000000-8999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:52:38,761 - src.aggregate_batch_ngram_counts - INFO - table size: 7861636\\n',\n",
       " '2023-05-02 21:52:38,764 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_9000000-9999999.parquet into table - start. executing query:\\n',\n",
       " 'INSERT INTO ngram_of_size_5_counts_table SELECT token_0, token_1, token_2, token_3, token_4, count FROM table_to_insert ON CONFLICT (token_0, token_1, token_2, token_3, token_4) DO UPDATE SET count = count + excluded.count;\\n',\n",
       " '2023-05-02 21:53:09,937 - src.aggregate_batch_ngram_counts - INFO - merging file data\\\\5\\\\count_table_9000000-9999999.parquet into table - end\\n',\n",
       " '2023-05-02 21:53:09,948 - src.aggregate_batch_ngram_counts - INFO - table size: 8023776\\n',\n",
       " '2023-05-02 21:53:31,214 - src.aggregate_batch_ngram_counts - INFO - aggregate batch ngram counts - end\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze time requirements\n",
    "# collect data from the logs\n",
    "log_file = Path('./logs/log.log')\n",
    "with log_file.open('r') as f:\n",
    "    log_lines = f.readlines()\n",
    "log_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c887f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37834a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebbd8e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"2023-05-02 20:20:33,385 - src.count_ngrams_in_batches - INFO - started working on samples 20000000-20999999;memory (MB): {'total': 8066, 'used': 6084, 'available': 1982}\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_line = log_lines[1]\n",
    "example_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d3b53af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find the last start time for the `count_ngrams_in_batches` directory\n",
    "datetime_regex = r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}'\n",
    "module_name_regex = r'\\w+\\.\\w+'\n",
    "message_regex = r'.*'\n",
    "log_line_regex = f'(?P<datetime>{datetime_regex}),\\\\d+ - ' \\\n",
    "                 f'(?P<module_name>{module_name_regex}) - \\\\w+ - ' \\\n",
    "                 f'(?P<message>{message_regex})'\n",
    "log_line_regex = re.compile(log_line_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ebc718b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datetime': '2023-05-02 20:20:33',\n",
       " 'module_name': 'src.count_ngrams_in_batches',\n",
       " 'message': \"started working on samples 20000000-20999999;memory (MB): {'total': 8066, 'used': 6084, 'available': 1982}\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_line_regex.match(example_line).groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "172de9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable \n",
    "\n",
    "\n",
    "def match_regex_condition(log_line: str) -> bool:\n",
    "    return log_line_regex.match(log_line) is not None\n",
    "\n",
    "def module_name_condition(log_line: str) -> bool:\n",
    "    return log_line_regex.match(log_line).groupdict()['module_name'] == 'src.count_ngrams_in_batches'\n",
    "\n",
    "def start_line_condition(log_line: str) -> bool:\n",
    "    return log_line_regex.match(log_line).groupdict()['message'] == 'Starting to count ngrams in batches'\n",
    "    \n",
    "def end_line_condition(log_line: str) -> bool:\n",
    "    return log_line_regex.match(log_line).groupdict()['message'] == 'Finished counting ngrams in batches'\n",
    "\n",
    "def compose_filter(filters: Iterable, iterable: Iterable) -> Iterable:\n",
    "    for f in filters:\n",
    "        iterable = filter(f, iterable)\n",
    "    return iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ade8aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_line_time(log_line: str) -> datetime:\n",
    "    log_time_str = log_line_regex.match(log_line).group('datetime')\n",
    "    datetime_fmt = '%Y-%m-%d %H:%M:%S'\n",
    "    return datetime.strptime(log_time_str, datetime_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea71cf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 5, 2, 20, 19, 48)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_lines = list(compose_filter([match_regex_condition, module_name_condition, start_line_condition], log_lines))\n",
    "last_start_line = start_lines[-1]\n",
    "last_start_line\n",
    "last_start_time = get_log_line_time(last_start_line)\n",
    "last_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f79ce2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 5, 2, 21, 1, 47)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_lines = list(compose_filter([match_regex_condition, module_name_condition, end_line_condition], log_lines))\n",
    "last_end_line = end_lines[-1]\n",
    "last_end_line\n",
    "last_end_time = get_log_line_time(last_end_line)\n",
    "last_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c28330e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2519"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time_seconds = (last_end_time - last_start_time).seconds\n",
    "total_time_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b07ab346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming that the time is linear with the number of workers and the number of tokens in the dataset, \n",
    "#  this should be approximately correct\n",
    "def compute_expected_time_seconds(n_tokens_expected: int, n_workers_expected: int) -> float:\n",
    "    worker_factor = n_workers / n_workers_expected\n",
    "    n_tokens_factor = n_tokens_expected / n_tokens_processed\n",
    "    time_expected_seconds = total_time_seconds * worker_factor * n_tokens_factor\n",
    "    return time_expected_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cec1ffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected time for wikipedia with n_workers=3 is 37.962 hours\n"
     ]
    }
   ],
   "source": [
    "wikipedia_n_workers = 3\n",
    "wikipedia_expected_time_seconds = compute_expected_time_seconds(n_tokens_wikipedia, wikipedia_n_workers)\n",
    "print(f'expected time for wikipedia with n_workers={wikipedia_n_workers} '\n",
    "      f'is {wikipedia_expected_time_seconds / 3600:.3f} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eacfadcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected time for RedPijama with n_workers=10 is 23.726 days\n"
     ]
    }
   ],
   "source": [
    "red_pijama_n_workers = 10\n",
    "red_pijama_expected_time_seconds = compute_expected_time_seconds(n_tokens_red_pijama, red_pijama_n_workers)\n",
    "red_pijama_expected_time_hours = red_pijama_expected_time_seconds / 3600\n",
    "red_pijama_expected_time_days = red_pijama_expected_time_hours / 24\n",
    "print(f'expected time for RedPijama with n_workers={red_pijama_n_workers} '\n",
    "      f'is {red_pijama_expected_time_days:.3f} days')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pmi_masking)",
   "language": "python",
   "name": "pmi_masking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
